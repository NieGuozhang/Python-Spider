# 聚焦爬虫- 爬取页面中指定的页面内容- 编码流程    - 指定URL    - 发起请求    - 获取响应数据    - 数据解析    - 数据持久化存储## 数据解析分类- 正则 （语言比较广泛）- bs4（只能用于Python语言）- **xpath**(重点，通用性比较强)## 数据解析原理概述- 解析的局部文本内容都会在标签之间或者在标签对应的属性中进行存储- 过程    - 进行指定标签的定位    - 标签或者标签对应的属性中存储的数据进行提取（解析）    ## bs进行数据解析- 原理    - 实例化一个BeautifulSoup对象，并且将页面源码加载到该对象中    - 通过调用BeautifulSoup对象中相关的属性或者方法进行标签定位和数据提取- 环境安装：    - `pip install bs4`    - `pip install lxml` ——安装解析器- 如何实例化BeautifulSoup对象？    - `from bs4 import BeautifulSoup`    - 对象的实例化        - 将本地的HTML文档数据加载到该对象中            `fp = open('./XX.html', 'r', encoding='utf-8')             soup = BeautifulSoup(fp, 'lxml')`        - 将互联网上获取的页面源码数据加载到该对象中            `page_text = response.text             soup = BeautifulSoup(page_text, 'lxml')`    - 提供的用于数据解析的方法和属性        - soup.tagName返回的是HTML中第一次出现的tagName标签            - 如：`print(soup.a)` 打印的是页面中第一个a标签内容        - soup.find('tagName')            - 返回的是HTML中第一次出现的tagName标签,作用和soup.tagName一样                - 如：`soup.find('a')` 页面中第一个a标签内容            - 属性定位                - `print(soup.find('div', class_='top-nav'))`        - soup.findAll('tagName')            - 返回符合要求的所有标签，是一个列表        - soup.select()            - select('某种选择器（id,class,标签...选择器）'), 返回的是一个列表            - 层级选择器                - `print(soup.select('.top-nav > ul > li > a'))` >表示的是一个层级                - `print(soup.select('.top-nav > ul  a'))` 空格表示的是多个层级        - 获取标签之间的文本数据            - `soup.a.text/string/get_text()`            - text/get_text():可以获取某一标签中所有文本内容            - string只能获取某标签下直系的文本内容        - 获取标签中属性值            - `soup.a['href']`        